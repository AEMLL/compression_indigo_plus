{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exisiting pre-trained INDIGO can be run using the inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run inference.py \\\n",
    "    -i testdata/lr_medium --task restoration \\\n",
    "    --eta 0.5 --aligned  --use_fp16 \\\n",
    "    --config_indigo configs/sample/indigo_syn.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The INN segment of the architecture can be retrained using the train.py script below. The training script employs BasicSR framework to optimise CINN weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disable distributed.\n",
      "Path already exists. Rename it to /rds/general/user/aem21/home/FYP/compression_indigo_plus/inn/experiments/BasicSR_Train_archived_20250408_135931\n",
      "Path already exists. Rename it to /rds/general/user/aem21/home/FYP/compression_indigo_plus/inn/tb_logger/BasicSR_Train_archived_20250408_135931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 13:59:31,740 INFO: \n",
      "                ____                _       _____  ____\n",
      "               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n",
      "              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n",
      "             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n",
      "            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n",
      "     ______                   __   __                 __      __\n",
      "    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n",
      "   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n",
      "  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n",
      "  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n",
      "    \n",
      "Version Information: \n",
      "\tBasicSR: 1.4.2\n",
      "\tPyTorch: 2.5.1+cu124\n",
      "\tTorchVision: 0.20.1+cu124\n",
      "2025-04-08 13:59:31,740 INFO: \n",
      "  name: BasicSR_Train\n",
      "  model_type: CINNModel\n",
      "  scale: 4\n",
      "  num_gpu: 1\n",
      "  manual_seed: 0\n",
      "  datasets:[\n",
      "    train:[\n",
      "      name: FFHQJPEGTrain\n",
      "      type: FFHQJPEGDataset\n",
      "      dataroot_gt: datasets/ffhq/train\n",
      "      io_backend:[\n",
      "        type: disk\n",
      "      ]\n",
      "      gt_size: 1024\n",
      "      use_flip: True\n",
      "      use_rot: True\n",
      "      use_shuffle: True\n",
      "      num_worker_per_gpu: 3\n",
      "      batch_size_per_gpu: 8\n",
      "      dataset_enlarge_ratio: 1\n",
      "      prefetch_mode: None\n",
      "      phase: train\n",
      "      scale: 4\n",
      "    ]\n",
      "    val:[\n",
      "      name: FFHQJPEGVal\n",
      "      type: FFHQJPEGDataset\n",
      "      dataroot_gt: datasets/ffhq/val\n",
      "      io_backend:[\n",
      "        type: disk\n",
      "      ]\n",
      "      phase: val\n",
      "      scale: 4\n",
      "    ]\n",
      "  ]\n",
      "  network_g:[\n",
      "    type: RWNN\n",
      "    offset: 0.5\n",
      "    LiftNet_iter: 2\n",
      "    basic_block_type: rb_cres_kdsr\n",
      "    net_kdsr: None\n",
      "    kdsr: 1\n",
      "  ]\n",
      "  path:[\n",
      "    pretrain_network_g: None\n",
      "    strict_load_g: True\n",
      "    resume_state: None\n",
      "    experiments_root: /rds/general/user/aem21/home/FYP/compression_indigo_plus/inn/experiments/BasicSR_Train\n",
      "    models: /rds/general/user/aem21/home/FYP/compression_indigo_plus/inn/experiments/BasicSR_Train/models\n",
      "    training_states: /rds/general/user/aem21/home/FYP/compression_indigo_plus/inn/experiments/BasicSR_Train/training_states\n",
      "    log: /rds/general/user/aem21/home/FYP/compression_indigo_plus/inn/experiments/BasicSR_Train\n",
      "    visualization: /rds/general/user/aem21/home/FYP/compression_indigo_plus/inn/experiments/BasicSR_Train/visualization\n",
      "  ]\n",
      "  train:[\n",
      "    optim_g:[\n",
      "      type: Adam\n",
      "      lr: 2e-05\n",
      "      weight_decay: 0.001\n",
      "      betas: [0.9, 0.99]\n",
      "    ]\n",
      "    scheduler:[\n",
      "      type: MultiStepLR\n",
      "      milestones: [50000]\n",
      "      gamma: 0.5\n",
      "    ]\n",
      "    total_iter: 1000\n",
      "    warmup_iter: -1\n",
      "    l2_opt:[\n",
      "      type: MSELoss\n",
      "      loss_weight: 1.0\n",
      "      reduction: mean\n",
      "    ]\n",
      "  ]\n",
      "  val:[\n",
      "    val_freq: 5000.0\n",
      "    save_img: True\n",
      "    metrics:[\n",
      "      psnr:[\n",
      "        type: calculate_psnr\n",
      "        crop_border: 4\n",
      "        test_y_channel: False\n",
      "      ]\n",
      "      niqe:[\n",
      "        type: calculate_niqe\n",
      "        crop_border: 4\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  logger:[\n",
      "    print_freq: 100\n",
      "    save_checkpoint_freq: 5000.0\n",
      "    use_tb_logger: True\n",
      "    wandb:[\n",
      "      project: None\n",
      "      resume_id: None\n",
      "    ]\n",
      "  ]\n",
      "  dist: False\n",
      "  rank: 0\n",
      "  world_size: 1\n",
      "  auto_resume: False\n",
      "  is_train: True\n",
      "  root_path: /rds/general/user/aem21/home/FYP/compression_indigo_plus/inn\n",
      "\n",
      "2025-04-08 13:59:31,787 INFO: Dataset [FFHQJPEGDataset] - FFHQJPEGTrain is built.\n",
      "2025-04-08 13:59:31,787 INFO: Training statistics:\n",
      "\tNumber of train images: 1600\n",
      "\tDataset enlarge ratio: 1\n",
      "\tBatch size per gpu: 8\n",
      "\tWorld size (gpu number): 1\n",
      "\tRequire iter number per epoch: 200\n",
      "\tTotal epochs: 5; iters: 1000.\n",
      "2025-04-08 13:59:31,793 INFO: Dataset [FFHQJPEGDataset] - FFHQJPEGVal is built.\n",
      "2025-04-08 13:59:31,793 INFO: Number of val images/folders in FFHQJPEGVal: 400\n",
      "2025-04-08 13:59:31,803 INFO: Network [RWNN] is created.\n",
      "2025-04-08 13:59:31,823 INFO: Network: RWNN, with parameters: 488,960\n",
      "2025-04-08 13:59:31,823 INFO: RWNN(\n",
      "  (transform_net): ImageTransform(\n",
      "    (split): LazyWaveletTransform()\n",
      "    (inn): InvertibleNet(\n",
      "      (lifts): ModuleList(\n",
      "        (0-3): 4 x LiftNet(\n",
      "          (p): PredictorNet(\n",
      "            (net): ResNet(\n",
      "              (convin): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "              (blocks): ModuleList(\n",
      "                (0-1): 2 x ResidualBlock_CRes_kdsr(\n",
      "                  (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (act): ReLU(inplace=True)\n",
      "                  (fc): Sequential(\n",
      "                    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (convout): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (u): UpdaterNet(\n",
      "            (net): ResNet(\n",
      "              (convin): Conv2d(9, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "              (blocks): ModuleList(\n",
      "                (0-1): 2 x ResidualBlock_CRes_kdsr(\n",
      "                  (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (act): ReLU(inplace=True)\n",
      "                  (fc): Sequential(\n",
      "                    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (convout): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2025-04-08 13:59:31,824 INFO: Loss [MSELoss] is created.\n",
      "2025-04-08 13:59:31,825 INFO: Model [CINNModel] is created.\n",
      "2025-04-08 13:59:31,891 INFO: Start training from epoch: 0, iter: 0\n",
      "2025-04-08 14:01:15,501 INFO: [Basic..][epoch:  0, iter:     100, lr:(2.000e-05,)] [eta: 0:15:04, time (data): 1.036 (0.026)] l_l2: 6.2177e-03 \n",
      "2025-04-08 14:02:58,948 INFO: [Basic..][epoch:  0, iter:     200, lr:(2.000e-05,)] [eta: 0:13:34, time (data): 1.035 (0.021)] l_l2: 3.1915e-03 \n",
      "2025-04-08 14:04:43,112 INFO: [Basic..][epoch:  1, iter:     300, lr:(2.000e-05,)] [eta: 0:11:58, time (data): 1.034 (0.015)] l_l2: 3.9548e-03 \n",
      "2025-04-08 14:06:26,473 INFO: [Basic..][epoch:  1, iter:     400, lr:(2.000e-05,)] [eta: 0:10:16, time (data): 1.034 (0.015)] l_l2: 3.6202e-03 \n",
      "2025-04-08 14:08:10,890 INFO: [Basic..][epoch:  2, iter:     500, lr:(2.000e-05,)] [eta: 0:08:34, time (data): 1.034 (0.015)] l_l2: 2.7838e-03 \n",
      "2025-04-08 14:09:54,282 INFO: [Basic..][epoch:  2, iter:     600, lr:(2.000e-05,)] [eta: 0:06:51, time (data): 1.034 (0.015)] l_l2: 2.4108e-03 \n",
      "2025-04-08 14:11:38,509 INFO: [Basic..][epoch:  3, iter:     700, lr:(2.000e-05,)] [eta: 0:05:09, time (data): 1.034 (0.015)] l_l2: 2.7595e-03 \n",
      "2025-04-08 14:13:21,830 INFO: [Basic..][epoch:  3, iter:     800, lr:(2.000e-05,)] [eta: 0:03:25, time (data): 1.033 (0.015)] l_l2: 2.1041e-03 \n",
      "2025-04-08 14:15:05,964 INFO: [Basic..][epoch:  4, iter:     900, lr:(2.000e-05,)] [eta: 0:01:42, time (data): 1.034 (0.015)] l_l2: 1.9227e-03 \n",
      "2025-04-08 14:16:49,314 INFO: [Basic..][epoch:  4, iter:   1,000, lr:(2.000e-05,)] [eta: -1 day, 23:59:59, time (data): 1.034 (0.015)] l_l2: 2.1535e-03 \n",
      "2025-04-08 14:16:50,130 INFO: End of training. Time consumed: 0:17:18\n",
      "2025-04-08 14:16:50,131 INFO: Save the latest model.\n",
      "2025-04-08 14:18:11,368 INFO: Validation FFHQJPEGVal\n",
      "\t # psnr: 27.5718\tBest: 27.5718 @ 1001 iter\n",
      "\t # niqe: 6.5987\tBest: 6.5987 @ 1001 iter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run inn/train.py -opt inn/options/cinn_option.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indigo",
   "language": "python",
   "name": "indigo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
